{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = dj.schema('microns_ta3p100')\n",
    "ta3p100 = dj.create_virtual_module('ta3p100', 'microns_ta3p100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta3p100.CurrentSegmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyramidal_cell_rel = ta3p100.AllenSoma & (ta3p100.AllenSomaClass & 'cell_class=\"excitatory\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta3p100.Decimation & ta3p100.CurrentSegmentation & 'decimation_ratio=0.10' & pyramidal_cell_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class CleansedMesh(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    # Cleansed of floating artifacts and isolated vertices.\n",
    "    -> ta3p100.Decimation\n",
    "    ---\n",
    "    n_vertices        : bigint\n",
    "    n_triangles       : bigint\n",
    "    vertices          : longblob\n",
    "    triangles         : longblob\n",
    "    \"\"\"\n",
    "    \n",
    "    def generate_neighborhood(self, triangles, num_vertices):\n",
    "        neighborhood = dict()\n",
    "        for i in range(num_vertices):\n",
    "            neighborhood[i] = set()\n",
    "        for node1, node2, node3 in triangles:\n",
    "            neighborhood[node1].update([node2, node3])\n",
    "            neighborhood[node2].update([node1, node3])\n",
    "            neighborhood[node3].update([node1, node2])\n",
    "        return neighborhood\n",
    "    \n",
    "    def set_search_first(self, starting_node, neighborhood):\n",
    "        \"\"\"\n",
    "        Modified Depth-First-Search utilizing sets to reduce duplicate checks:\n",
    "\n",
    "        Neighborhood must be a dict with the keys being the vertex indices!\n",
    "        \"\"\"    \n",
    "        visited_nodes = set()\n",
    "        temp_stack = set()\n",
    "        temp_stack.add(starting_node)\n",
    "        while len(temp_stack) > 0:\n",
    "            starting_node = temp_stack.pop()\n",
    "            if starting_node not in visited_nodes:\n",
    "                visited_nodes.add(starting_node)\n",
    "                temp_stack.update(neighborhood[starting_node])\n",
    "        return list(visited_nodes)\n",
    "    \n",
    "    def get_connected_portions(self, neighborhood):\n",
    "        neighborhood_copy = neighborhood.copy()\n",
    "        portions = []\n",
    "        while len(neighborhood_copy) > 0:\n",
    "            starting_node = next(iter(neighborhood_copy))\n",
    "            portion = self.set_search_first(starting_node, neighborhood_copy)\n",
    "            for node in portion:\n",
    "                neighborhood_copy.pop(node)\n",
    "            portions.append(portion)\n",
    "        return portions\n",
    "\n",
    "    def get_largest_portion_index(self, portions):\n",
    "        portion_lengths = [len(portion) for portion in portions]\n",
    "        return portion_lengths.index(max(portion_lengths))\n",
    "\n",
    "    def get_largest_portion(self, portions):\n",
    "        return portions[self.get_largest_portion_index(portions)]\n",
    "\n",
    "    def remove_floating_artifacts(self, mesh):    \n",
    "        mesh_copy = mesh.copy()\n",
    "\n",
    "        # Generating the neighborhoods gets quite expensive for full resolution meshes, but the searches are extremely quick.\n",
    "        neighborhood = self.generate_neighborhood(mesh_copy['triangles'], len(mesh_copy['vertices']))\n",
    "        portions = self.get_connected_portions(neighborhood)\n",
    "\n",
    "        main_mesh_body_index = self.get_largest_portion_index(portions)\n",
    "        triangle_removal_nodes = portions[main_mesh_body_index:] + portions[:main_mesh_body_index + 1]\n",
    "\n",
    "        new_triangles = []\n",
    "        main_body_portion = set(self.get_largest_portion(portions))\n",
    "        for i, triangle in enumerate(mesh_copy['triangles']):\n",
    "            node1 = triangle[0]\n",
    "            if node1 in main_body_portion:\n",
    "                new_triangles.append(triangle)\n",
    "        mesh_copy['triangles'] = np.array(new_triangles)\n",
    "\n",
    "        return mesh_copy\n",
    "\n",
    "    def remove_isolated_vertices(self, mesh):\n",
    "        mesh_copy = mesh.copy()\n",
    "\n",
    "        neighborhood = self.generate_neighborhood(mesh_copy['triangles'], len(mesh_copy['vertices']))\n",
    "        isolated_nodes = [portion.pop() for portion in self.get_connected_portions(neighborhood) if len(portion) == 1]\n",
    "\n",
    "        vertices = mesh_copy['vertices']\n",
    "        triangles = mesh_copy['triangles']\n",
    "\n",
    "        if len(isolated_nodes) > 0:\n",
    "            num_isolated_nodes_passed = 0\n",
    "            isolated_nodes_set = set(isolated_nodes)\n",
    "            count_to_decrement = np.zeros(len(vertices))\n",
    "            for i in range(len(vertices)):\n",
    "                if i in isolated_nodes_set:\n",
    "                    num_isolated_nodes_passed += 1\n",
    "                else:\n",
    "                    count_to_decrement[i] = num_isolated_nodes_passed\n",
    "\n",
    "            for i, triangle in enumerate(triangles):\n",
    "                start = time.time()\n",
    "                node1, node2, node3 = triangle\n",
    "                triangles[i][0] -= count_to_decrement[node1]\n",
    "                triangles[i][1] -= count_to_decrement[node2]\n",
    "                triangles[i][2] -= count_to_decrement[node3]\n",
    "\n",
    "            vertex_list = list(vertices)\n",
    "            for i, isolated_node in enumerate(isolated_nodes):\n",
    "                vertex_list.pop(isolated_node - i)\n",
    "\n",
    "        mesh_copy['vertices'] = np.array(vertex_list)\n",
    "\n",
    "        return mesh_copy\n",
    "    \n",
    "    key_source = ta3p100.Decimation & ta3p100p100.CurrentSegmentation & 'decimation_ratio=0.35' & pyramidal_cell_rel \n",
    "    \n",
    "    def make(self, key):\n",
    "        full_start = time.time()\n",
    "        \n",
    "        print(key['segment_id'], key['decimation_ratio'], \":\")\n",
    "        start = time.time()\n",
    "                \n",
    "        mesh = (ta3p100.Decimation & key).fetch1()\n",
    "        print(key['segment_id'], \"mesh fetched.\", time.time() - start)\n",
    "        start = time.time()\n",
    "                \n",
    "        neighborhood = self.generate_neighborhood(mesh['triangles'], len(mesh['vertices']))\n",
    "        print(key['segment_id'] , \"neighborhood generated.\", time.time() - start)\n",
    "        start = time.time()\n",
    "        \n",
    "        mesh = self.remove_floating_artifacts(mesh)\n",
    "        print(key['segment_id'], \"floating artifacts removed.\", time.time() - start)\n",
    "        start = time.time()\n",
    "        \n",
    "        mesh = self.remove_isolated_vertices(mesh)\n",
    "        print(key['segment_id'], \"isolated nodes removed.\", time.time() - start)\n",
    "        start = time.time()\n",
    "                \n",
    "        key['n_vertices'] = len(mesh['vertices'])\n",
    "        key['n_triangles'] = len(mesh['triangles'])\n",
    "        key['vertices'] = mesh['vertices']\n",
    "        key['triangles'] = mesh['triangles']\n",
    "        \n",
    "        self.insert1(key)\n",
    "        print(key['segment_id'], \"key successfully inserted.\", time.time() - start)\n",
    "        start = time.time()\n",
    "        \n",
    "        print(\"This took \", time.time() - full_start, \"seconds.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "CleansedMesh().populate()#reserve_jobs=True)\n",
    "print(\"Final:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "\n",
    "def generate_neighborhood(triangles, num_vertices):\n",
    "    neighborhood = dict()\n",
    "    for i in range(num_vertices):\n",
    "        neighborhood[i] = set()\n",
    "    for node1, node2, node3 in triangles:\n",
    "        neighborhood[node1].update([node2, node3])\n",
    "        neighborhood[node2].update([node1, node3])\n",
    "        neighborhood[node3].update([node1, node2])\n",
    "    return neighborhood\n",
    "\n",
    "def compress_compartments(neighborhood, vertex_labels):\n",
    "    boundary_clusters = dict()\n",
    "    for unique_label in np.unique(vertex_labels):\n",
    "        boundary_clusters[unique_label] = dict()#list()\n",
    "\n",
    "    starting_node = 0 # This assumes that there are no disconnected portions... I should actually figure out exactly what's going on here.\n",
    "    visited_nodes = set()\n",
    "    temp_stack = set()\n",
    "    temp_stack.add(starting_node)    \n",
    "    while len(temp_stack) > 0:\n",
    "        starting_node = temp_stack.pop()\n",
    "        if starting_node not in visited_nodes:\n",
    "            same_label_neighbors = set()\n",
    "            node_label = vertex_labels[starting_node]\n",
    "            is_on_boundary = False\n",
    "            for neighboring_node in neighborhood[starting_node]: # Think about if I truly need the same labeled neighbors...\n",
    "                                                                 # Only way for it to be truly self contained right?\n",
    "                if node_label == vertex_labels[neighboring_node]:\n",
    "                    same_label_neighbors.add(neighboring_node)\n",
    "                else:\n",
    "                    is_on_boundary = True\n",
    "            if is_on_boundary:\n",
    "#                 boundary_clusters[node_label].append((starting_node, same_label_neighbors))\n",
    "                boundary_clusters[node_label][starting_node] = same_label_neighbors\n",
    "                \n",
    "            visited_nodes.add(starting_node)\n",
    "            temp_stack.update(neighborhood[starting_node])\n",
    "    return boundary_clusters\n",
    "\n",
    "def _separate_compartment(neighborhood, cluster, boundary_points):\n",
    "    components = dict()\n",
    "    compartment_index = 0\n",
    "    while len(cluster) > 0:\n",
    "        visited_nodes = set()\n",
    "        temp_stack = set()\n",
    "        temp_stack.add(next(iter(cluster)))\n",
    "        boundaries_hit = set()\n",
    "        while len(temp_stack) > 0:\n",
    "            starting_node = temp_stack.pop()\n",
    "            if starting_node not in visited_nodes:\n",
    "                visited_nodes.add(starting_node)\n",
    "                if starting_node in boundary_points:\n",
    "                    boundaries_hit.add(starting_node)\n",
    "                    temp_stack.update(cluster[starting_node])\n",
    "                else:\n",
    "                    temp_stack.update(neighborhood[starting_node])\n",
    "        [cluster.pop(boundary_hit) for boundary_hit in boundaries_hit]        \n",
    "        components[compartment_index] = visited_nodes\n",
    "        compartment_index += 1\n",
    "    return components\n",
    "\n",
    "def separate_compartments(neighborhood, boundary_clusters):\n",
    "    compartment_components = dict()\n",
    "    boundary_clusters_copy = boundary_clusters.copy()\n",
    "    for label, boundary_cluster in boundary_clusters_copy.items():\n",
    "        cluster = dict()\n",
    "        boundary_points = set()\n",
    "        for node, neighbors in boundary_cluster.items():\n",
    "            boundary_points.add(node)\n",
    "            cluster[node] = neighbors\n",
    "        components = _separate_compartment(neighborhood, cluster, boundary_points)\n",
    "        compartment_components[label] = components\n",
    "    return compartment_components\n",
    "        \n",
    "############################################################################################################# For Below\n",
    "\n",
    "@schema\n",
    "class Compartment(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> ta3p100.CleansedMesh\n",
    "    ---\n",
    "    \"\"\"\n",
    "\n",
    "    class Component(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> Compartment\n",
    "        compartment_type   : varchar(16)        # Basal, Apical, spine head, etc.\n",
    "        component_index    : smallint unsigned  # Which sub-compartment of a certain label this is.\n",
    "        ---\n",
    "        n_vertex_indices   : bigint\n",
    "        n_triangle_indices : bigint\n",
    "        vertex_indices     : longblob           # preserved indices of each vertex of this sub-compartment\n",
    "        triangle_indices   : longblob           # preserved indices of each triangle of this sub-compartment\n",
    "        \"\"\"\n",
    "    \n",
    "    key_source = ta3p100.CleansedMesh & ta3p100.CurrentSegmentation & 'decimation_ratio=0.35'\n",
    "\n",
    "    def make(self, key):\n",
    "        def generate_triangle_neighborhood(triangles):\n",
    "            \"\"\"\n",
    "            Maps each vertex node to every triangle they appear in.\n",
    "            \"\"\"\n",
    "            triangle_neighborhood = dict()\n",
    "            for i in range(len(triangles)):\n",
    "                triangle_neighborhood[i] = set()\n",
    "            for i, (node1, node2, node3) in enumerate(triangles):\n",
    "                triangle_neighborhood[node1].add(i)\n",
    "                triangle_neighborhood[node2].add(i)\n",
    "                triangle_neighborhood[node3].add(i)\n",
    "            return triangle_neighborhood\n",
    "        \n",
    "        def generate_component_keys(key, components, triangles, triangle_neighborhood, labeled_triangles):\n",
    "            for label_key, compartment in components.items():\n",
    "                for component_index, component in compartment.items():\n",
    "                    label_name = (ta3p100.LabelKey & dict(numeric=label_key)).fetch1('description')\n",
    "                    vertex_indices = np.array(list(component))\n",
    "                    triangle_indices = np.unique([triangle_index for node in component\n",
    "                                                  for triangle_index in triangle_neighborhood[node]\n",
    "                                                  if labeled_triangles[triangle_index] == label_key])\n",
    "                    set_vertex_indices = set(vertex_indices)\n",
    "                    true_triangle_indices = []\n",
    "                    for triangle_index in triangle_indices:\n",
    "                        node1, node2, node3 = triangles[triangle_index]\n",
    "                        if node1 in set_vertex_indices:\n",
    "                            if node2 in set_vertex_indices:\n",
    "                                if node3 in set_vertex_indices:\n",
    "                                    true_triangle_indices.append(triangle_index)                        \n",
    "                    triangle_indices = np.array(true_triangle_indices)\n",
    "                    yield dict(key,\n",
    "                               compartment_type=label_name,\n",
    "                               component_index=component_index,\n",
    "                               n_vertex_indices=len(vertex_indices),\n",
    "                               n_triangle_indices=len(triangle_indices),\n",
    "                               vertex_indices=vertex_indices,\n",
    "                               triangle_indices=triangle_indices)\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        mesh = (ta3p100.CleansedMesh & key).fetch1()\n",
    "        labels = (ta3p100.CoarseLabel & key).fetch1()\n",
    "        \n",
    "        neighborhood = generate_neighborhood(mesh['triangles'], len(mesh['vertices']))\n",
    "        boundary_clusters = compress_compartments(neighborhood, labels['vertices'])\n",
    "        components = separate_compartments(neighborhood, boundary_clusters)\n",
    "        triangle_neighborhood = generate_triangle_neighborhood(mesh['triangles'])\n",
    "\n",
    "        self.insert1(key)\n",
    "        Compartment.Component().insert(generate_component_keys(key, components, mesh['triangles'],\n",
    "                                                               triangle_neighborhood, labels['labeled_triangles']))\n",
    "\n",
    "        print(key['segment_id'], \"finished separating components:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compartment.populate(reserve_jobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.time() - true_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
